{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_file import load_dataframe\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "file_loc = os.getenv(\"file_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded into dataframe sucessfully\n",
      "    Invoice ID Branch       City Customer type  Gender  \\\n",
      "0  750-67-8428      A     Yangon        Member  Female   \n",
      "1  226-31-3081      C  Naypyitaw        Normal  Female   \n",
      "2  631-41-3108      A     Yangon        Normal    Male   \n",
      "3  123-19-1176      A     Yangon        Member    Male   \n",
      "4  373-73-7910      A     Yangon        Normal    Male   \n",
      "\n",
      "             Product line  Unit price  Quantity   Tax 5%     Total       Date  \\\n",
      "0       Health and beauty       74.69         7  26.1415  548.9715   1/5/2019   \n",
      "1  Electronic accessories       15.28         5   3.8200   80.2200   3/8/2019   \n",
      "2      Home and lifestyle       46.33         7  16.2155  340.5255   3/3/2019   \n",
      "3       Health and beauty       58.22         8  23.2880  489.0480  1/27/2019   \n",
      "4       Sports and travel       86.31         7  30.2085  634.3785   2/8/2019   \n",
      "\n",
      "    Time      Payment    cogs  gross margin percentage  gross income  Rating  \n",
      "0  13:08      Ewallet  522.83                 4.761905       26.1415     9.1  \n",
      "1  10:29         Cash   76.40                 4.761905        3.8200     9.6  \n",
      "2  13:23  Credit card  324.31                 4.761905       16.2155     7.4  \n",
      "3  20:33      Ewallet  465.76                 4.761905       23.2880     8.4  \n",
      "4  10:37      Ewallet  604.17                 4.761905       30.2085     5.3  \n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=file_loc)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "df = load_dataframe(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2259fcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d694787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1000 chunks from 1000 original documents\n",
      "Total chunks created: 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chuck_documents(documents,hunk_size=550, chunk_overlap=50):\n",
    "    if not documents:\n",
    "        print(\"No documents to chunk.\")\n",
    "        return None\n",
    "    try:\n",
    "        text_split = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=hunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        chunked_docs = text_split.split_documents(documents)\n",
    "        print(f\"Created {len(chunked_docs)} chunks from {len(documents)} original documents\")\n",
    "        return chunked_docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating text splitter: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "chunk_doc = chuck_documents(documents)\n",
    "print(f\"Total chunks created: {len(chunk_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfa8146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Invoice ID: 401-18-8016\n",
      "Branch: B\n",
      "City: Mandalay\n",
      "Customer type: Member\n",
      "Gender: Female\n",
      "Product line: Sports and travel\n",
      "Unit price: 98.13\n",
      "Quantity: 1\n",
      "Tax 5%: 4.9065\n",
      "Total: 103.0365\n",
      "Date: 1/21/2019\n",
      "Time: 17:36\n",
      "Payment: Cash\n",
      "cogs: 98.13\n",
      "gross margin percentage: 4.761904762\n",
      "gross income: 4.9065\n",
      "Rating: 8.9' metadata={'source': 'D:\\\\K_AgentiAI\\\\DASH-AI_Agent\\\\Data\\\\CSV\\\\supermarket_sales.csv', 'row': 498}\n"
     ]
    }
   ],
   "source": [
    "print(chunk_doc[498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba59e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def vector_db_setup(chunk_doc,collection_name=\"Supermarket_sales\",persist_directory=\"./chroma_langchain_db\"):\n",
    "    if not chunk_doc :\n",
    "        print(\"No documents to add to vector store\")\n",
    "        return None,None\n",
    "    try:\n",
    "        print(\"please wait while model is Initializing.....\")\n",
    "        embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "        vector_store = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embed,\n",
    "            persist_directory=persist_directory,\n",
    "         )\n",
    "        print(f\"Adding {len(chunk_doc)} document chunks to vector store...\")\n",
    "        vector_store.add_documents(chunk_doc)\n",
    "        retriver =  vector_store.as_retriever(\n",
    "            search_kwargs={\"k\": 4}  # Return top 4 most relevant chunks\n",
    "        ) \n",
    "        print(\"Vector store setup complete.\")\n",
    "        return vector_store,retriver\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector store: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a32f5ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please wait while model is Initializing.....\n",
      "Adding 1000 document chunks to vector store...\n",
      "Vector store setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Make sure chunked_docs is already created from previous steps\n",
    "vector_store, retriever = vector_db_setup(chunk_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ced70e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors in store: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total vectors in store:\", vector_store._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0481790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
